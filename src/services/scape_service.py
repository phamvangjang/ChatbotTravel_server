import pandas as pd
import uuid
from src.models.attraction import Attraction
from src.models.base import db
import json
import re
import os
import math

def extract_price_from_string(price_string):
    """
    Tr√≠ch xu·∫•t gi√° v√© t·ª´ chu·ªói ph·ª©c t·∫°p h·ªó tr·ª£ 5 th·ª© ti·∫øng
    
    Args:
        price_string (str): Chu·ªói ch·ª©a th√¥ng tin gi√° v√©
        
    Returns:
        float: Gi√° v√© trung b√¨nh ho·∫∑c None n·∫øu kh√¥ng th·ªÉ tr√≠ch xu·∫•t
    """
    if not price_string or pd.isna(price_string):
        return None
    
    price_string = str(price_string).strip()
    
    # T·ª´ kh√≥a mi·ªÖn ph√≠ cho 5 th·ª© ti·∫øng
    free_keywords = {
        'vi': ['mi·ªÖn ph√≠', 'free', 'gratis', '0'],
        'en': ['free', 'no charge', 'gratis', '0'],
        'zh': ['ÂÖçË¥π', 'ÂÖçË≤ª', 'ÂÖçÁ•®', '0'],
        'ja': ['ÂÖ•Â†¥ÁÑ°Êñô', 'ÁÑ°Êñô', '„Éï„É™„Éº', '0'],
        'ko': ['Î¨¥Î£å', 'Î¨¥Î£å ÏûÖÏû•', 'Í≥µÏßú', '0']
    }
    
    # Ki·ªÉm tra t·ª´ kh√≥a mi·ªÖn ph√≠
    price_lower = price_string.lower()
    for lang_keywords in free_keywords.values():
        for keyword in lang_keywords:
            if keyword in price_lower:
                return 0.0
    
    # Patterns ƒë·ªÉ t√¨m s·ªë trong c√°c ƒë·ªãnh d·∫°ng kh√°c nhau
    # H·ªó tr·ª£: 65.000, 65,000, 65000, 65,000.00
    price_patterns = [
        r'(\d{1,3}(?:[.,]\d{3})*(?:\.\d+)?)',  # 65.000, 65,000, 1,500, 30.5
        r'(\d+(?:\.\d+)?)',  # 65000, 15000.5
    ]
    
    prices = []
    for pattern in price_patterns:
        matches = re.findall(pattern, price_string)
        for match in matches:
            # Lo·∫°i b·ªè d·∫•u ph·∫©y v√† d·∫•u ch·∫•m ph√¢n c√°ch h√†ng ngh√¨n
            clean_price = match.replace(',', '').replace('.', '')
            try:
                price = float(clean_price)
                # Ch·ªâ l·∫•y gi√° h·ª£p l√Ω (t·ª´ 0 ƒë·∫øn 10 tri·ªáu VNƒê)
                if 0 <= price <= 10000000:
                    prices.append(price)
            except ValueError:
                continue
    
    if not prices:
        return None
    
    # Tr·∫£ v·ªÅ gi√° trung b√¨nh n·∫øu c√≥ nhi·ªÅu gi√°
    return sum(prices) / len(prices)

def clean_value(value):
    """
    L√†m s·∫°ch gi√° tr·ªã ƒë·ªÉ tr√°nh l·ªói NaN trong MySQL
    
    Args:
        value: Gi√° tr·ªã c·∫ßn l√†m s·∫°ch
        
    Returns:
        Gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch
    """
    if pd.isna(value) or value is None:
        return None
    
    # N·∫øu l√† s·ªë v√† l√† NaN
    if isinstance(value, (int, float)) and math.isnan(value):
        return None
    
    # N·∫øu l√† string v√† r·ªóng
    if isinstance(value, str) and value.strip() == '':
        return None
    
    return value

def import_csv_to_attractions(csv_file_path):
    """
    Import d·ªØ li·ªáu t·ª´ file CSV v√†o b·∫£ng Attractions
    
    Args:
        csv_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV
        
    Returns:
        dict: K·∫øt qu·∫£ import v·ªõi s·ªë l∆∞·ª£ng records ƒë√£ import v√† th√¥ng b√°o l·ªói n·∫øu c√≥
    """
    try:
        # ƒê·ªçc file CSV
        df = pd.read_csv(csv_file_path)
        
        # Debug: In ra c√°c c·ªôt c√≥ trong CSV
        print(f"üîç Debug - Available columns in CSV: {list(df.columns)}")
        print(f"üîç Debug - First few rows of ngon_ngu column:")
        if 'ngon_ngu' in df.columns:
            print(df['ngon_ngu'].head())
        else:
            print("‚ùå Column 'ngon_ngu' not found in CSV!")
        
        # Ki·ªÉm tra c√°c c·ªôt b·∫Øt bu·ªôc
        required_columns = ['ten_dia_diem', 'dia_chi']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            return {
                'success': False,
                'error': f'‚ùå Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {", ".join(missing_columns)}',
                'details': {
                    'missing_columns': missing_columns,
                    'available_columns': list(df.columns),
                    'total_columns': len(df.columns),
                    'suggestion': f'H√£y ƒë·∫£m b·∫£o file CSV c√≥ c√°c c·ªôt: {", ".join(required_columns)}'
                }
            }
        
        # Mapping c√°c c·ªôt t·ª´ CSV sang model
        column_mapping = {
            'ten_dia_diem': 'name',
            'mo_ta': 'description', 
            'loai_dia_diem': 'category',
            'khu_vuc': 'address',  # Gi·∫£ s·ª≠ khu_vuc map v·ªõi address
            'dia_chi': 'address',
            'tu_khoa': 'tags',
            'thoi_gian_hoat_dong': 'opening_hours',
            'gia_ve': 'price',
            'danh_gia': 'rating',
            'hinh_anh': 'image_url',
            'Latitude': 'latitude',
            'Longitude': 'longitude',
            'ngon_ngu': 'language',  # C·ªôt ng√¥n ng·ªØ map v·ªõi language field
        }
        
        imported_count = 0
        errors = []
        
        for index, row in df.iterrows():
            try:
                # T·∫°o ID duy nh·∫•t cho attraction
                attraction_id = str(uuid.uuid4())
                
                # X·ª≠ l√Ω tags - chuy·ªÉn t·ª´ string sang list n·∫øu c·∫ßn
                tags = clean_value(row.get('tu_khoa', ''))
                if isinstance(tags, str) and tags:
                    # Gi·∫£ s·ª≠ tags ƒë∆∞·ª£c ph√¢n t√°ch b·∫±ng d·∫•u ph·∫©y
                    tags_list = [tag.strip() for tag in tags.split(',') if tag.strip()]
                else:
                    tags_list = []
                
                # X·ª≠ l√Ω gi√° v√© t·ª´ chu·ªói ph·ª©c t·∫°p (h·ªó tr·ª£ ƒëa ng√¥n ng·ªØ)
                gia_ve_raw = clean_value(row.get('gia_ve', ''))
                processed_price = extract_price_from_string(gia_ve_raw) if gia_ve_raw else None
                
                # Ki·ªÉm tra d·ªØ li·ªáu b·∫Øt bu·ªôc
                ten_dia_diem = clean_value(row.get('ten_dia_diem', ''))
                dia_chi = clean_value(row.get('dia_chi', ''))
                language = clean_value(row.get('ngon_ngu', ''))
                
                if not ten_dia_diem:
                    raise ValueError("T√™n ƒë·ªãa ƒëi·ªÉm kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
                
                if not dia_chi:
                    raise ValueError("ƒê·ªãa ch·ªâ kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
                
                # X·ª≠ l√Ω c√°c tr∆∞·ªùng kh√¥ng c√≥ trong CSV v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh
                # phone_number kh√¥ng c√≥ trong CSV n√™n set null
                phone_number = None
                aliases = []  # JSON array r·ªóng
                
                # X·ª≠ l√Ω c√°c gi√° tr·ªã s·ªë ƒë·ªÉ tr√°nh NaN
                rating_value = clean_value(row.get('danh_gia', 0))
                if rating_value is not None:
                    try:
                        rating_float = float(rating_value)
                        rating_final = rating_float if not math.isnan(rating_float) else 0.0
                    except (ValueError, TypeError):
                        rating_final = 0.0
                else:
                    rating_final = 0.0
                
                # X·ª≠ l√Ω latitude v√† longitude
                lat_value = clean_value(row.get('Latitude'))
                if lat_value is not None:
                    try:
                        lat_float = float(lat_value)
                        latitude_final = lat_float if not math.isnan(lat_float) else None
                    except (ValueError, TypeError):
                        latitude_final = None
                else:
                    latitude_final = None
                
                lng_value = clean_value(row.get('Longitude'))
                if lng_value is not None:
                    try:
                        lng_float = float(lng_value)
                        longitude_final = lng_float if not math.isnan(lng_float) else None
                    except (ValueError, TypeError):
                        longitude_final = None
                else:
                    longitude_final = None
                
                # T·∫°o attraction object v·ªõi t·∫•t c·∫£ c√°c tr∆∞·ªùng ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch
                attraction = Attraction(
                    id=attraction_id,
                    name=ten_dia_diem,
                    description=clean_value(row.get('mo_ta', '')),
                    category=clean_value(row.get('loai_dia_diem', '')),
                    address=dia_chi,
                    tags=tags_list,
                    opening_hours=clean_value(row.get('thoi_gian_hoat_dong', '')),
                    price=processed_price,
                    rating=rating_final,
                    image_url=clean_value(row.get('hinh_anh', '')),
                    latitude=latitude_final,
                    longitude=longitude_final,
                    # C√°c tr∆∞·ªùng kh√¥ng c√≥ trong CSV - set gi√° tr·ªã m·∫∑c ƒë·ªãnh
                    phone_number=phone_number,
                    language=language,
                    aliases=aliases
                )
                
                # Th√™m v√†o database
                db.session.add(attraction)
                imported_count += 1
                
            except Exception as e:
                error_msg = f"‚ùå D√≤ng {index + 1}: {str(e)}"
                if ten_dia_diem:
                    error_msg += f" (T√™n: {ten_dia_diem})"
                errors.append(error_msg)
                continue
        
        # Commit t·∫•t c·∫£ thay ƒë·ªïi
        db.session.commit()
        
        return {
            'success': True,
            'imported_count': imported_count,
            'total_rows': len(df),
            'errors': errors
        }
        
    except pd.errors.EmptyDataError:
        return {
            'success': False,
            'error': '‚ùå File CSV tr·ªëng ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu',
            'details': {
                'file_path': csv_file_path,
                'file_size': os.path.getsize(csv_file_path) if os.path.exists(csv_file_path) else 0,
                'suggestion': 'Ki·ªÉm tra file CSV c√≥ ch·ª©a d·ªØ li·ªáu kh√¥ng'
            }
        }
    except pd.errors.ParserError as e:
        return {
            'success': False,
            'error': f'‚ùå L·ªói parse CSV: {str(e)}',
            'details': {
                'file_path': csv_file_path,
                'suggestion': 'Ki·ªÉm tra ƒë·ªãnh d·∫°ng CSV v√† delimiter. ƒê·∫£m b·∫£o file ƒë∆∞·ª£c l∆∞u v·ªõi ƒë·ªãnh d·∫°ng CSV chu·∫©n.',
                'common_issues': [
                    'D·∫•u ph·∫©y trong d·ªØ li·ªáu kh√¥ng ƒë∆∞·ª£c escape',
                    'Delimiter kh√¥ng ƒë√∫ng (n√™n d√πng d·∫•u ph·∫©y)',
                    'File c√≥ encoding kh√¥ng ƒë√∫ng'
                ]
            }
        }
    except Exception as e:
        # Rollback n·∫øu c√≥ l·ªói
        db.session.rollback()
        return {
            'success': False,
            'error': f'‚ùå L·ªói kh√¥ng mong mu·ªën: {str(e)}',
            'details': {
                'file_path': csv_file_path,
                'suggestion': 'Ki·ªÉm tra l·∫°i file CSV v√† th·ª≠ l·∫°i. N·∫øu l·ªói v·∫´n ti·∫øp t·ª•c, h√£y li√™n h·ªá admin.',
                'error_type': type(e).__name__
            },
            'imported_count': 0,
            'total_rows': 0,
            'errors': []
        }
